<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
<title>Voice Agent — Guarded v3</title>
<style>
  :root { color-scheme: light dark; }
  body { font-family: -apple-system, system-ui, Segoe UI, Roboto, Helvetica, Arial, sans-serif; margin:24px; line-height:1.44; }
  h1 { margin:0 0 12px; font-size:26px; }
  .row { display:flex; gap:10px; flex-wrap:wrap; margin:10px 0; }
  button { font-size:16px; padding:10px 14px; border-radius:10px; border:1px solid #bbb; }
  button:disabled{ opacity:.6 }
  #status { font-weight:700; }
  #log { min-height:220px; border:1px solid #ddd; border-radius:10px; padding:12px; background:#f7f7f7;
         white-space:pre-wrap; overflow:auto; font-family:ui-monospace,SFMono-Regular,Menlo,monospace; }
  .note { opacity:.8; }

  /* overlay for auto mode */
  #tapOverlay {
    position: fixed; inset: 0; display: none; place-items:center;
    background: color-mix(in oklab, Canvas 70%, black 30%);
    backdrop-filter: blur(4px);
    z-index: 9999; text-align:center; padding: 24px;
  }
  #tapOverlay .card {
    border: 1px solid #ccc; border-radius: 14px; padding: 18px 20px; max-width: 460px;
    background: color-mix(in oklab, Canvas 85%, black 15%);
  }
  #tapOverlay h2 { margin: 0 0 8px; font-size: 20px; }
  #tapOverlay p { margin: 0; opacity: .85; }
</style>
</head>
<body>
<h1>Voice Agent — Guarded v3</h1>

<div class="row">
  <button id="beep-wa">Beep (WebAudio)</button>
  <button id="beep-tag">Beep (AudioTag)</button>
  <button id="nudge">Nudge audio</button>
  <button id="unlock-mic">Unlock mic</button>
</div>

<div class="row">
  <button id="start">Start voice agent</button>
  <button id="stop" disabled>Stop</button>
  <button id="force" disabled>Force reply</button>
</div>

<div class="note">Status: <span id="status">idle</span></div>
<audio id="out" autoplay playsinline></audio>
<pre id="log"></pre>

<!-- one-time user gesture for iOS audio -->
<div id="tapOverlay" role="dialog" aria-modal="true">
  <div class="card">
    <h2>Tap to allow audio</h2>
    <p>iPhone needs a quick tap to enable sound. Tap anywhere to start the voice agent.</p>
  </div>
</div>

<script>
const $ = s => document.querySelector(s);
const logEl = $('#log');
function log(...a){ logEl.textContent += a.join(' ') + '\n'; logEl.scrollTop = logEl.scrollHeight; }
function setStatus(s){ $('#status').textContent = s; }
const sleep = ms => new Promise(r => setTimeout(r, ms));

let pc=null, dc=null, localStream=null;
let AGENT_STARTING = false;
let AGENT_STARTED  = false;

let audioCtx;
async function beepWebAudio(ms=150, freq=880){
  try{
    const AC = window.AudioContext || window.webkitAudioContext;
    if(!audioCtx) audioCtx = new AC();
    if(audioCtx.state==='suspended') { log('webaudio suspended; resuming'); await audioCtx.resume(); }
    const o = audioCtx.createOscillator(), g = audioCtx.createGain();
    o.type='sine'; o.frequency.value=freq; g.gain.value=0.08;
    o.connect(g).connect(audioCtx.destination); o.start(); await sleep(ms); o.stop();
    log('WebAudio beep');
  }catch(e){ log('webaudio error:', e?.message||e); }
}
async function nudgeAudio(){ await beepWebAudio(60, 1200); log('WebAudio nudge OK'); }
function beepAudioTag(){
  try{
    const a = new Audio();
    a.setAttribute('playsinline','');
    a.src = "data:audio/wav;base64,UklGRkgAAABXQVZFZm10IBAAAAABAAEAESsAACJWAAACABYAaGFkYQAAAAAAAP8AAP//AAD//wAA//8AAP//AAD//wAA//8AAP8AAP8AAP//AAD//wAA//8AAP//AAD//wAA//8AAP//AAD//wAA//8AAP//AAD//wAA//8AAP//AAD//wAA";
    a.play().then(()=>log('AudioTag beep')).catch(err=>log('AudioTag play error:', err));
  }catch(e){ log('AudioTag exception:', e?.message||e); }
}
async function unlockMicOnce(){
  log('requesting microphone…');
  try{
    const s = await navigator.mediaDevices.getUserMedia({ audio:true });
    s.getTracks().forEach(t=>t.stop());
    log('microphone OK');
    return true;
  }catch(err){
    log('mic error:', err?.name||err?.message||err);
    return false;
  }
}

function updateButtons(){
  $('#start').disabled = AGENT_STARTING || AGENT_STARTED;
  $('#stop').disabled  = !(AGENT_STARTING || AGENT_STARTED);
  $('#force').disabled = !dc || dc.readyState!=='open';
}

async function startAgentOnce(){
  if (AGENT_STARTING || AGENT_STARTED){ log('start ignored (already starting/started)'); return; }
  AGENT_STARTING = true; updateButtons();
  let watchdog;
  try{
    setStatus('preparing…');
    log('start: step 1/7 nudge audio');
    await nudgeAudio();

    log('start: step 2/7 unlock mic');
    const micOk = await unlockMicOnce();
    if(!micOk){ setStatus('idle'); log('start aborted: mic not granted'); return; }

    log('start: step 3/7 fetch /session');
    watchdog = setTimeout(()=>{ log('watchdog: start seems stuck; retrying once'); AGENT_STARTING=false; updateButtons(); startAgentOnce(); }, 7000);

    const sessResp = await fetch('/session', { method:'POST' });
    if(!sessResp.ok){ throw new Error('session error '+sessResp.status); }
    const sess = await sessResp.json();
    log('start: got session');

    const clientSecret = sess?.client_secret?.value;
    const model = sess?.model || 'gpt-4o-realtime-preview-2024-12-17';
    if(!clientSecret) throw new Error('no client_secret');

    log('start: step 4/7 getUserMedia real');
    localStream = await navigator.mediaDevices.getUserMedia({ audio:true });

    log('start: step 5/7 create RTCPeerConnection');
    pc = new RTCPeerConnection();
    pc.onconnectionstatechange = () => log('pc state:', pc.connectionState);
    pc.oniceconnectionstatechange = () => log('ice state:', pc.iceConnectionState);
    pc.ontrack = (e)=>{ $('#out').srcObject = e.streams[0]; };

    dc = pc.createDataChannel('oai-events');
    dc.onopen  = () => { log('datachannel open'); updateButtons(); };
    dc.onclose = () => log('datachannel closed');
    dc.onmessage = (ev)=>log('event:', ev.data);

    for(const t of localStream.getTracks()) pc.addTrack(t, localStream);
    log('start: step 6/7 createOffer & setLocalDescription');
    const offer = await pc.createOffer({ offerToReceiveAudio:true });
    await pc.setLocalDescription(offer);

    log('start: step 7/7 POST offer to OpenAI');
    const answerSDP = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}`,{
      method:'POST',
      headers:{ 'Authorization':'Bearer '+clientSecret, 'Content-Type':'application/sdp' },
      body: offer.sdp
    }).then(r=>r.text());

    await pc.setRemoteDescription({ type:'answer', sdp:answerSDP });
    clearTimeout(watchdog);

    AGENT_STARTED = true;
    setStatus('listening');
    log('connected ✓ (speak to get a reply, or tap Force reply)');
    updateButtons();
  }catch(err){
    clearTimeout(watchdog);
    setStatus('error');
    log('start error:', err?.message||String(err));
  }finally{
    AGENT_STARTING = false; updateButtons();
  }
}

function stopAgent(){
  log('stopping…');
  try{ dc && dc.close(); }catch{}
  try{ pc && pc.close(); }catch{}
  try{ localStream && localStream.getTracks().forEach(t=>t.stop()); }catch{}
  dc=null; pc=null; localStream=null;
  AGENT_STARTED = false; AGENT_STARTING = false;
  setStatus('idle'); updateButtons();
}

function forceReply(){
  if(!dc || dc.readyState!=='open'){ log('force: channel not open'); return; }
  dc.send(JSON.stringify({ type:'response.create' }));
  log('force reply sent');
}

$('#beep-wa').onclick = () => beepWebAudio();
$('#beep-tag').onclick = () => beepAudioTag();
$('#nudge').onclick   = () => nudgeAudio();
$('#unlock-mic').onclick = () => unlockMicOnce();
$('#start').onclick   = () => startAgentOnce();
$('#stop').onclick    = () => stopAgent();
$('#force').onclick   = () => forceReply();

setStatus('idle'); updateButtons();

const tapOverlay = $('#tapOverlay');
function showTapOverlay(){ tapOverlay.style.display = 'grid'; }
function hideTapOverlay(){ tapOverlay.style.display = 'none'; }

window.addEventListener('load', async () => {
  const q = new URLSearchParams(location.search);
  if (q.get('auto') === '1') {
    // If audio context will be suspended, request a quick tap first.
    const AC = window.AudioContext || window.webkitAudioContext;
    const probe = new AC();
    if (probe.state === 'suspended') {
      showTapOverlay();
      const onTap = async () => {
        hideTapOverlay();
        document.removeEventListener('pointerdown', onTap, true);
        try { await probe.resume(); } catch {}
        await sleep(150);
        startAgentOnce();
      };
      document.addEventListener('pointerdown', onTap, true);
    } else {
      await sleep(400); // tiny paint delay
      startAgentOnce();
    }
  }
});
</script>
</body>
</html>
